{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376c67c-03f0-4dad-ad08-bdfb57cddb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/75981883/can-not-use-lightgbm-gpu-in-colab-lightgbmerror-no-opencl-device-found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e102150a-5bea-4536-9fce-e1699baf7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgbm\n",
    "X,y = make_classification(n_samples=8000000, n_features=100, n_classes=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161c67bc-5e42-4cba-8662-b4cbe5e488f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (572.20 MB) transferred to GPU in 0.218899 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (572.20 MB) transferred to GPU in 0.209727 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (572.20 MB) transferred to GPU in 0.218583 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (572.20 MB) transferred to GPU in 0.201185 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (572.20 MB) transferred to GPU in 0.220640 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (572.20 MB) transferred to GPU in 0.195685 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (572.20 MB) transferred to GPU in 0.226741 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 4060 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 100 dense feature groups (572.20 MB) transferred to GPU in 0.180730 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "15.2 s ± 655 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model = lgbm.LGBMClassifier(device=\"gpu\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a69d12-0f1d-4cc5-b666-593ab8ba5d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.705334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.650878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.642219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.657765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.693241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.667635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.680509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "[LightGBM] [Info] Number of positive: 3000249, number of negative: 2999751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.688424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500042 -> initscore=0.000166\n",
      "[LightGBM] [Info] Start training from score 0.000166\n",
      "42.1 s ± 381 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model = lgbm.LGBMClassifier(device=\"cpu\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa37c9a-a958-498d-955a-51d71b83f7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
